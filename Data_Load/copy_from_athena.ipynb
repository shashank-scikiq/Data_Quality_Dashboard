{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_src = \"..//open-data-webapp//\"\n",
    "\n",
    "load_dotenv(env_src+\"loc.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = os.getenv(\"AWS_ACCESS_KEY\")\n",
    "pwd = os.getenv(\"AWS_SECRET_KEY\")\n",
    "bucket = os.getenv(\"S3_STAGING_DIR\")\n",
    "region = os.getenv(\"AWS_REGION\")\n",
    "schema = os.getenv(\"SCHEMA_NAME\")\n",
    "db = os.getenv(\"DATABASE_NAME\")\n",
    "table_name = os.getenv(\"TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect(\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_KEY\"),\n",
    "    region_name=os.getenv(\"AWS_REGION\"),\n",
    "    schema_name=os.getenv(\"SCHEMA_NAME\"),\n",
    "    s3_staging_dir=os.getenv(\"S3_STAGING_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = engine.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_val = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = cursor.execute(\"\"\"SELECT * FROM default.nhm_order_fulfillment_subset_v1 \n",
    "                     WHERE date(date_parse(\"O_Created Date & Time\", '%%Y-%%m-%%dT%%H:%%i:%%s')) = DATE %(day_val)s\"\"\", \n",
    "                     {\"day_val\": \"2024-01-01\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = val.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Python File Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out.csv\",'w', newline='',encoding='utf8') as f:\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Writing with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(\"jan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing writing data with Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_parquet(\"jan_z.parquet\",compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is faster to convert the dataset from Query object to csv using Python file method. \n",
    "- It is easier and memory efficient to convert csv into parquet with zstd compression using pandas. Can do this manually however any change in column name/ columns will require those columns to be identified manually. \n",
    "- Best method is to read the data into query format, write to csv using python file handling, and convert it to parquet using pandas. Then load it into the target database. \n",
    "- Each step can branch out into multiple threads for faster parallel processing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
